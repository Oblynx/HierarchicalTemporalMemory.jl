"""
`SPParams{Nin,Nsp}` holds the algorithm parameters for a spatial pooler with nomenclature
similar to [source](https://www.frontiersin.org/articles/10.3389/fncom.2017.00111/full)

The dimension parameters are problem-specific and should be the first to be specified.

The tuning parameters have sensible defaults, which should be .
All gated features are enabled by default.

# Parameters

## Dimensions
- `száµ¢â‚™ = (32,32)`: input dimensions
- `szâ‚›â‚š = (32,32)`: output dimensions
- `Î³ = 6`: receptive field radius (how large an input area an output minicolumn maps to)

## Algorithm tuning
- `s = .02`: average output sparsity
- `prob_synapse = .5`: probability for each element of the `száµ¢â‚™ Ã— szâ‚›â‚š` space to be a synapse.
  Elements that roll below this value don't form a synapse and don't get a permanence value.
  If this is very low, the proximal synapses matrix can become sparse.
- `Î¸_permanence01 = .5`: synapse permanence connection threshold
- `pâº_01 = .1 , pâ»_01 = .02`: synapse permanence adaptation rate (see [`ProximalSynapses`](@ref))
- `Î¸_stimulus_activate = 1`: minicolumn absolute activation threshold
- `Tboost = 200.0`: boosting mechanism's moving average filter period
- `Î² = 1.0`: boosting strength

## Feature gates
- `enable_local_inhibit = true`
- `enable_learning = true`
- `enable_boosting = true`
"""
@with_kw struct SPParams{Nin,Nsp}
  # dimensions
  száµ¢â‚™::Union{NTuple{Nin,Int},Int}     = (32,32); @assert all(száµ¢â‚™.>0)
  szâ‚›â‚š::Union{NTuple{Nsp,Int},Int}     = (50,50); @assert all(szâ‚›â‚š.>0)
  Î³::Int                    = 6;       @assert Î³>0

  # tuning
  s::Float32                = .02;     @assert s>0
  prob_synapse::Float32     = .5;      @assert 0<=prob_synapse<=1
  Î¸_permanence01::Float32   = .5;      @assert 0<=Î¸_permanence01<=1
  pâº_01::Float32            = .1;      @assert 0<=pâº_01<=1
  pâ»_01::Float32            = .02;     @assert 0<=pâ»_01<=1
  Î¸_permanence::ğ•Šğ•¢        = round(ğ•Šğ•¢, Î¸_permanence01*typemax(ğ•Šğ•¢))
  pâº::ğ•Šğ•¢                  = round(ğ•Šğ•¢, pâº_01*typemax(ğ•Šğ•¢))
  pâ»::ğ•Šğ•¢                  = round(ğ•Šğ•¢, pâ»_01*typemax(ğ•Šğ•¢))
  Î¸_stimulus_activate::Int  = 1;       @assert Î¸_stimulus_activate>=0
  Tboost::Float32           = 200;     @assert Tboost>0
  Î²::Float32                = 1;       @assert Î²>0

  # feature gates
  enable_local_inhibit::Bool= true
  enable_learning::Bool     = true
  enable_boosting::Bool     = true
  @assert zero(ğ•Šğ•¢)<=Î¸_permanence<=typemax(ğ•Šğ•¢)
  @assert zero(ğ•Šğ•¢)<=pâº<=typemax(ğ•Šğ•¢)
  @assert zero(ğ•Šğ•¢)<=pâ»<=typemax(ğ•Šğ•¢)
end

"""
`TMParams` holds the algorithm parameters for a Temporal Memory with nomenclature
similar to [source]()

## Dimensions
- `Nc = 2500`: number of columns
- `k = 10`: cells per column
- `Nâ‚™ = k Nc` neurons in layer. The `Nâ‚›` number of dendritic segments
  is variable

## Tuning
- `pâº_01 = .12 , pâ»_01 = .04 âˆˆ [0,1]`: synapse permanence adaptation rate (see [`ProximalSynapses`](@ref))
- `LTD_pâ»_01 = .002 âˆˆ [0,1]`: synapse long term depression rate
- `Î¸_permanence = .5*typemax(ğ•Šğ•¢) âˆˆ ğ•Šğ•¢`: synapse permanence connection threshold
- `init_permanence = .4*typemax(ğ•Šğ•¢) âˆˆ ğ•Šğ•¢`: permanence of a newly-grown synapse
- `synapseSampleSize = 25 âˆˆ â„•`: target number of matching synapses per dendrite.
  Represents how many bits the dendrite targets to recognize the input.
  Dendrites with fewer synapses matching the input might grow new synapses.
- `Î¸_stimulus_activate = 14 âˆˆ â„•`: number of matching synapses needed to depolarize the dendrite
- `Î¸_stimulus_learn = 12 âˆˆ â„•`: number of matching synapses that are insufficient to depolarize the
  dendrite, but sufficient to trigger learning. `Î¸_stimulus_learn <= Î¸_stimulus_activate`

## Feature gates
- `enable_learning = true`
"""
@with_kw struct TMParams
  # dimensions
  Nc::Int                  = 2500;    @assert Nc>0
  k::Int                   = 10;      @assert k>0
  Nâ‚™::Int                  = k*Nc;    @assert Nâ‚™>0

  # tuning
  pâº_01::Float32           = .12;     @assert 0<=pâº_01<=1
  pâ»_01::Float32           = .04;     @assert 0<=pâ»_01<=1
  LTD_pâ»_01::Float32       = .002;    @assert 0<=LTD_pâ»_01<=1
  pâº::ğ•Šğ•¢                 = round(ğ•Šğ•¢,pâº_01*typemax(ğ•Šğ•¢))
  pâ»::ğ•Šğ•¢                 = round(ğ•Šğ•¢,pâ»_01*typemax(ğ•Šğ•¢))
  LTD_pâ»::ğ•Šğ•¢             = round(ğ•Šğ•¢,LTD_pâ»_01*typemax(ğ•Šğ•¢))
  Î¸_permanence::ğ•Šğ•¢       = round(ğ•Šğ•¢,.5typemax(ğ•Šğ•¢))
  init_permanence::ğ•Šğ•¢    = round(ğ•Šğ•¢,.4typemax(ğ•Šğ•¢))
  synapseSampleSize::Int   = 25;      @assert synapseSampleSize>0
  Î¸_stimulus_activate::Int = 14;      @assert Î¸_stimulus_activate>0
  Î¸_stimulus_learn::Int    = 12;      @assert 0 < Î¸_stimulus_learn <= Î¸_stimulus_activate

  # feature gates
  enable_learning::Bool    = true
end

# Created from TMParams
@with_kw struct DistalSynapseParams
  pâº::ğ•Šğ•¢                 = round(ğ•Šğ•¢,pâº_01*typemax(ğ•Šğ•¢))
  pâ»::ğ•Šğ•¢                 = round(ğ•Šğ•¢,pâ»_01*typemax(ğ•Šğ•¢))
  LTD_pâ»::ğ•Šğ•¢             = round(ğ•Šğ•¢,LTD_pâ»_01*typemax(ğ•Šğ•¢))
  Î¸_permanence::ğ•Šğ•¢       = round(ğ•Šğ•¢,.5typemax(ğ•Šğ•¢))
  init_permanence::ğ•Šğ•¢    = round(ğ•Šğ•¢,.4typemax(ğ•Šğ•¢))
  synapseSampleSize::Int   = 25;      @assert synapseSampleSize>0
  Î¸_stimulus_learn::Int    = 12;      @assert 0 < Î¸_stimulus_learn
end
DistalSynapseParams(tmParams::TMParams)= begin
  @unpack pâº, pâ», LTD_pâ», Î¸_permanence,
      init_permanence, synapseSampleSize, Î¸_stimulus_learn = tmParams
  DistalSynapseParams(pâº, pâ», LTD_pâ», Î¸_permanence,
      init_permanence, synapseSampleSize, Î¸_stimulus_learn)
end
